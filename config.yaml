model:
  force_download: false # 强制下载所有模型文件。默认: false, 选择: false true
  skip_download: false # 跳过模型文件下载。默认: false, 选择: false true

log:
  log_level: info # 设置日志级别。默认: info, 选择: trace debug info warn error critical

task:
  per_task_thread_count: 3 # 指定每个任务的线程数量。减小此项可降低内存和显存占用。默认: 1。

inference_session:
  device_id: 0 # 指定进行推理的GPU设备id. 默认: 0
  providers: cpu # 指定模型推理时的提供者。默认: cpu, 选择: tensor_rt cuda cpu
  enable_engine_cache: true # 设置TensorRT引擎是否启用缓存。默认: true, 选择: false true
  enable_embed_engine: true # 设置是否开启embed engine。默认: true, 选择: false true
  trt_max_workspace_size: 2.5 # 设置trt_max_workspace_size，单位为GB。默认: none, 示例: 2.5

memory:
  processor_memory_strategy: strict # strict: 需要用到时才创建，用完则立即销毁。tolerant：进入程序便创建所有用户指定的processor，程序结束时才销毁。示例: strict