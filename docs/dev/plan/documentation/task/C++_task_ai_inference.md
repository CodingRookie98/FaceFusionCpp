# {AI Inference} å®æ–½ä»»åŠ¡å•

> **æ ‡å‡†å‚è€ƒ & è·¨æ–‡æ¡£é“¾æ¥**:
> *   æ‰€å±è®¡åˆ’: [é¡¹ç›®æ–‡æ¡£è¾“å‡ºå®æ–½è®¡åˆ’](../C++_plan_documentation.md)
> *   ç°æœ‰ä»£ç : `inference_session.ixx`

## 0. ä»»åŠ¡å‰éªŒè¯ (AI Agent è‡ªæ£€)

*   [x] **çˆ¶è®¡åˆ’**: æˆ‘å·²é˜…è¯» `docs/dev/plan/documentation/C++_plan_documentation.md`ã€‚
*   [x] **å†²çªæ£€æŸ¥**: æˆ‘å·²éªŒè¯å³å°†åˆ›å»ºçš„æ–‡ä»¶åä¸å­˜åœ¨ã€‚

## 1. ä»»åŠ¡æ¦‚è§ˆ

### 1.1 ç›®æ ‡
> @brief ç¼–å†™ `ai_inference.md` (ä¸­è‹±åŒè¯­)ï¼Œè§£ææ¨ç†å¼•æ“å°è£…ã€‚

*   **ç›®æ ‡**: åˆ›å»º `docs/dev/en/ai_inference.md` å’Œ `docs/dev/zh/ai_inference.md`ã€‚
*   **æ‰€å±è®¡åˆ’**: [é¡¹ç›®æ–‡æ¡£è¾“å‡ºå®æ–½è®¡åˆ’](../C++_plan_documentation.md)
*   **ä¼˜å…ˆçº§**: P2-Standard

### 1.2 æ¨¡å—å˜æ›´æ¸…å•

| æ¨¡å—ç±»å‹ | æ–‡ä»¶å | å˜æ›´ç±»å‹ | è¯´æ˜ |
| :--- | :--- | :--- | :--- |
| **Dev Doc (EN)** | `docs/dev/en/ai_inference.md` | **New** | è‹±æ–‡ç‰ˆ AI æ¨ç†æ–‡æ¡£ |
| **Dev Doc (ZH)** | `docs/dev/zh/ai_inference.md` | **New** | ä¸­æ–‡ç‰ˆ AI æ¨ç†æ–‡æ¡£ |

---

## 2. TDD å®ç°æµç¨‹

### 2.1 ğŸ”´ Red: éªŒè¯æ–‡ä»¶ç¼ºå¤±
*   [ ] æ£€æŸ¥ `docs/dev/en/ai_inference.md` ä¸å­˜åœ¨ã€‚
*   [ ] æ£€æŸ¥ `docs/dev/zh/ai_inference.md` ä¸å­˜åœ¨ã€‚

### 2.2 ğŸŸ¢ Green: ç¼–å†™å†…å®¹
#### 2.2.1 å†…å®¹å¤§çº²
1.  **Overview (æ¦‚è§ˆ)**
    *   Wrapper around ONNX Runtime.
    *   Provider priority (TensorRT -> CUDA -> CPU).
2.  **Session Management (ä¼šè¯ç®¡ç†)**
    *   `InferenceSession`: RAII wrapper.
    *   `SessionPool`: LRU Cache / TTL.
3.  **Model Repository (æ¨¡å‹ä»“åº“)**
    *   Path resolution.
    *   Auto-download logic.
4.  **TensorRT Optimization (TensorRT ä¼˜åŒ–)**
    *   Engine caching (`.engine` files).
    *   First-run compilation.

### 2.3 ğŸ”µ Refactor: ä¼˜åŒ–ä¸æ£€æŸ¥
*   [ ] ç¡®ä¿æœ¯è¯­å‡†ç¡®ã€‚

---

## 3. éªŒè¯ä¸éªŒæ”¶

### 3.1 å¼€å‘è€…è‡ªæµ‹ (Checklist)
*   [ ] **é€»è¾‘å‡†ç¡®**: æè¿°ç¬¦åˆä»£ç å®ç°ã€‚

---
**æ‰§è¡Œäºº**: Antigravity
**å¼€å§‹æ—¥æœŸ**: 2026-02-12
